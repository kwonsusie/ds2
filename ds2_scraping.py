# -*- coding: utf-8 -*-
"""ds2_scraping

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QA5HEzrSBCiicsJSfmX9YXimXWi1L3ti

#スクレイピング
"""

from bs4 import BeautifulSoup
import requests #HTTP操作用
import time
import re

#アクセスしたいwebサイトのurl
url = "https://www.house-direct.jp/column/sleeptime/"
r=requests.get(url)
r.encoding = 'utf-8'
scr_sl = BeautifulSoup(r.text, 'html.parser')

#サイトから獲得
scr_list = scr_sl.find_all('tbody')
for k in scr_list:
  scr_text = k.get_text()

scr_text = scr_text.strip()
scr_text = scr_text.strip('\n')
scr_lines = list(scr_text.split('\n'))
print(scr_lines)

"""# DBの作成

"""

import sqlite3
!pwd

# DB作成と接続
path = '/content/'
db_name = 'heikin_time.sqlite'
con = sqlite3.connect(path + db_name)
print(type(con))

# SQLを実行するためのオブジェクトを取得
cur = con.cursor()

create_table_heikintime = 'CREATE TABLE IF NOT EXISTS heikin (sleep_table TEXT);'
cur.execute(create_table_heikintime)

# データを挿入
for sleep_table in scr_lines:
   insert_time = "INSERT INTO heikin (sleep_table) VALUES (?);"
   cur.execute(insert_time, (scr_lines,))


#cur.execute(insert_time, (scr_lines))

# DBの確認

# データを取得するSQL
sql_select = 'SELECT * FROM heikin;'

# SQLを実行
cur.execute(sql_select)

for r in cur:
  print(r)

#6．DBへの接続を閉じる
con.close()